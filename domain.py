from math import pi, sqrt, atan2, dist
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from os import path, getcwd

from teaming.Agent import Agent
from teaming.POI import POI
from teaming.room import Room
from time import sleep, time


class DiscreteRoverDomain:
    def __init__(self, p):
        self.p = p
        self.n_agents = p.n_agents  # number of agents
        self.n_agent_types = p.n_agent_types  # number of types of agents
        self.size = p.size  # size of the world
        self.time_steps = p.time_steps  # time steps per epoch
        self.n_rooms = len(p.rooms) + 1  # number of rooms, INCLUDING hallway
        self.room_poi_cts = p.rooms.copy()

        self.n_poi_types = np.shape(self.room_poi_cts[0])[0]  # how many types of POIs - allows for calc of L
        self.poi_x_y = []  # to save POI xy locations
        self.theoretical_max_g = 0  # Maximum G if all POIs were perfectly captured
        self.vis = 0  # To visualize or not to visualize
        self.time = 0

        self.pois = []  # initialize POIs list
        self.n_pois = 0  # number of POIs is generated by rooms
        self.rooms = self.gen_world()
        self.agents = self.gen_agents()  # generate agents
        self.update_rms()
        # self.reset()                                # reset the system

    ################################# Setup Functions #################################

    def gen_world(self):

        room_dims, door_dims = self._gen_room_dims()
        hallway_poi = [0] * self.n_poi_types
        self.room_poi_cts.append(hallway_poi)
        p = [self.p for _ in range(len(self.room_poi_cts))]
        idxs = [i for i in range(len(self.room_poi_cts))]

        pois = []
        for i, poi_ct in enumerate(self.room_poi_cts):
            # generate POIs in each room
            poi_list = self.gen_rm_pois(i, room_dims[i], poi_ct)
            pois.append(poi_list)  # Add list of POIs for each room to list to generate rooms
            self.pois.extend(poi_list)  # Add individual POIs to overall list

        return list(map(Room, idxs, p, room_dims, door_dims, pois))

    def _gen_room_dims(self):
        room_dims = []
        # Hallway x, y positions
        hall_st = np.floor(self.size / 2)
        hall_lower = [0, hall_st]  # x, y of hallway lower left corner
        hall_upper = [self.size, hall_st + 1]  # x, y of hallway upper right corner
        hall_dims = [hall_lower, hall_upper]

        # Decide how many rooms are above / below the hallway
        n_rooms = int(len(self.p.rooms))
        n_upper = int(np.floor(n_rooms / 2))
        n_lower = n_upper
        # If there are rooms leftover
        if n_rooms - (n_upper + n_lower):
            # If there are leftovers after splitting into two groups, add one to the lower group
            n_lower = n_upper + 1

        # x axis dimensions
        upper_bins = np.linspace(0, self.size, n_upper + 1)
        lower_bins = np.linspace(0, self.size, n_lower + 1)
        upper_x = []
        lower_x = []
        upper_door_x = []
        lower_door_x = []
        for i in range(len(upper_bins) - 1):
            upper_x.append([upper_bins[i], upper_bins[i + 1]])
            upper_door_x.append((upper_bins[i] + upper_bins[i + 1]) / 2)
        for j in range(len(lower_bins) - 1):
            lower_x.append([lower_bins[j], lower_bins[j + 1]])
            lower_door_x.append((lower_bins[j] + lower_bins[j + 1]) / 2)

        # y axis dimensions
        upper_y = [[hall_st + 1, self.size] for _ in range(n_upper)]
        lower_y = [[0, hall_st] for _ in range(n_lower)]
        upper_dims = np.ndarray.tolist(np.dstack((upper_x, upper_y)))
        lower_dims = np.ndarray.tolist(np.dstack((lower_x, lower_y)))

        # Subtract / add 0.1 to dimensions so the doors are slightly outside the rooms
        # This is necessary so agents don't get stuck in the room
        lower_door_y = [hall_st + 0.1 for _ in range(n_lower)]
        upper_door_y = [hall_st + 1 - 0.1 for _ in range(n_upper)]

        lower_door_dims = list(zip(lower_door_x, lower_door_y))
        upper_door_dims = list(zip(upper_door_x, upper_door_y))

        # Add it all to one array
        all_rm_dims = []
        for rm in lower_dims:
            all_rm_dims.append(rm)
        for rm2 in upper_dims:
            all_rm_dims.append(rm2)
        all_rm_dims.append(hall_dims)
        # None is for the hallway
        all_door_dims = lower_door_dims + upper_door_dims + [None]
        return all_rm_dims, all_door_dims

    def gen_agents(self):
        """
        Generates a list of agents
        :return: list of agent objects at random initial locations
        """
        # creates an array of x, y positions for each agent
        # Agents start in the hallway
        X = np.random.uniform(0, 8, self.n_agents) + self.size // 2 - 4
        Y = np.random.uniform(0, 1, self.n_agents) + self.size // 2
        idxs = [i for i in range(self.n_agents)]
        # return an array of Agent objects at the specified locations
        # Agent initialization: x, y, idx, capabilties, type
        return [Agent(x, y, idx, np.random.random(self.n_pois), np.random.randint(0, self.n_agent_types), self.p)
                for x, y, idx in zip(X, Y, idxs)]

    def gen_rm_pois(self, rm_idx, dims, poi_nums):
        # Long list of what type each POI will be
        types = []
        for i, n in enumerate(poi_nums):
            types.extend([i] * n)

        # Unpack room dimensions
        [[rx0, ry0], [rx1, ry1]] = dims
        x = np.random.uniform(rx0, rx1, len(types))  # x locations for all POIs
        y = np.random.uniform(ry0, ry1, len(types))  # y locations for all POIs
        self.poi_x_y = np.array([x, y])  # Use this to save x,y locations
        idxs = []
        for _ in types:
            # Use the current number of POIs as the index
            # Since we index at 0, the index will always be the same as the number of POIs counted so far
            # This will also prevent idx conflicts from POIs in other rooms
            idxs.append(self.n_pois)
            self.n_pois += 1

        # Array of parameter objects and room id so the POIs have access to that info
        params = [self.p for _ in range(len(types))]
        rm_idxs = [rm_idx for _ in range(len(types))]

        return list(map(POI, idxs, x, y, params, types, rm_idxs))

    def save_poi_locs(self, fpath):
        np.save(fpath, self.poi_x_y)

    def move_pois(self):
        x = np.random.normal(0, 0.1, self.n_pois)  # x movement for all POIs
        y = np.random.normal(0, 0.1, self.n_pois)  # y movement for all POIs
        for i, poi in enumerate(self.pois):
            poi.x += x[i]
            poi.y += y[i]
            dims = [poi.x, poi.y]
            for d in dims:
                if d < 0:
                    d = 1
                elif d > self.size:
                    d = self.size - 1

    def reset(self):
        """
        Reset environment to initial configuration
        :return:
        """
        for a in self.agents:  # reset all agents to initial config
            a.reset()
        for p in self.pois:  # reset all POIs to initial config
            p.reset()
        for r in self.rooms:  # reset all rooms to initial config
            r.reset()
        self.update_rms()

    def new_env(self):
        self.rooms = self.gen_world()
        self.agents = self.gen_agents()  # generate agents
        self.update_rms()

    ################################# Run Sim Functions #################################
    def run_sim(self, policies):
        """
        This is set up to run one epoch for the number of time steps specified in the class definition.
        Tests a set of NN policies, one for each agent.
        Parameters
        ----------
        policies: a policy (assumes a NN) for each agent
        use_time: sets whether to use time in the agent state. Defaults to false

        Returns
        -------
        G: global reward
        """
        if len(policies) != self.n_agents:
            raise ValueError(
                f'number of policies should equal number of agents in system '
                f'(currently {self.n_agents} agents and {len(policies)} policies)')
        for i in range(len(policies)):
            self.agents[i].policy = policies[i]  # sets all agent policies
        for t in range(self.time_steps):
            self.time = t
            state = self.joint_state()
            actions = self.joint_actions(state)
            xy = [self.agents[0].x, self.agents[0].y]
            self.step(actions)
            if self.vis:
                self.view(t)
        return self.G()

    def step(self, actions):
        """
        perform one state transition given a list of actions for each agent
        :param actions:
        :return:
        """
        # update all agents
        for i, ag in enumerate(self.agents):
            # act = actions[i]
            # act_true = [x for x in act if x]        # Checks that actions are not all None

            # agents set a new goal at every time step
            act = actions[i]
            ag.xy_goal = act[:2]  # Unpack x, y target for agent
            ag.poi = act[2]  # Unpack POI if it exists (otherwise this will be None)
            ag.step()  # move agent toward POI
        self.update_rms()
        # refresh all POIs and reset which agents are currently viewing
        for j, poi in enumerate(self.pois):
            if self.p.strong_coupling:
                poi.refresh_strong()
            else:
                poi.refresh()
            poi.viewing = []  # if this gets reset at every step, the "viewing" check will only see the last time step

    def update_rms(self):
        # Reverse the order the rooms are checked in
        # If the hallway is checked last, it will overwrite any info about an agent being in a doorway (since doorways and hallway overlap)
        # Therefore the hallway gets checked first. Yes this is dumb.
        rm_check_order = [i for i in range(self.n_rooms)][::-1]
        # Update which room each agent is currently in
        for i in rm_check_order:
            rm = self.rooms[i]
            rm.agents_in_rm = []  # Clear room's list of agents so it can be recalculated
            for ag in self.agents:
                if rm.in_room(ag):
                    ag.curr_rm = rm.idx  # Update agent's current room
                    ag.update_rm_st()  # Update agent's state timer
                    rm.agents_in_rm.append(ag)  # Update room's list of agents for room state

    def joint_state(self):
        global_st = []
        for rm in self.rooms:
            global_st.append(rm.poi_state())

        joint_st = []
        for agent in self.agents:
            st = self.state(agent, global_st)  # calculates the state
            joint_st.append(st)
        return joint_st

    def joint_actions(self, joint_st):
        actions = []
        for i, agent in enumerate(self.agents):
            st = joint_st[i]
            act_array = agent.policy(st).detach().numpy()  # picks an action based on the policy
            act = self.action(agent, act_array)
            actions.append(act)  # save the action to list of actions
        return actions

    def state(self, agent, global_st):
        """
        Takes in an agent, returns the state and the relevant indices for the closest POI or agent in each region of each type
        :param agent:
        :param global_st:
        :return state, state_idx:
        """
        rm_st = []
        for i, rm in enumerate(global_st):
            rm_np = np.array(rm)
            # Multiplies binary value of whether to include that room in the state by the state
            # 0 if don't include / 1 if include
            # Any room that has not been visited recently will be all 0s
            incl_rm = agent.rm_in_state[i]
            if incl_rm:
                rm_st.append(incl_rm * rm_np)
            else:
                # Optimistic values - include values to encourage exploration
                rm_st.append([-1] * len(rm_np))
        # Flattens the matrix and adds the agent's current room to the end
        st = np.reshape(rm_st, (1, -1))[0]
        full_st = np.append(st, agent.curr_rm)
        return full_st

    def state_size(self):
        """
        State is how many of each POI type and agent type are in each room
        Plus one for the room the agent is currently in
        :return:
        state size
        """
        # return (self.n_rooms * (self.n_poi_types + self.n_agent_types)) + 1
        return (self.n_rooms * (self.n_poi_types)) + 1

    def action(self, agent, nn_output):
        """

        :param agent:
        :param nn_output: Assumes output from the NN a 1xN numpy array
        :return: agent, poi, or False (for no movement)
        """
        # Goal is [x, y, POI] - if goal is not a POI, then the last element is None
        goal = [None, None, None]

        # NN outputs are rooms x (agent types + poi types)
        nn_max_idx = np.argmax(nn_output)
        # Figure out room number - divide by number of POI types + agent types
        it_per_rm = self.n_poi_types # + self.n_agent_types
        goal_rm = int(nn_max_idx / it_per_rm)
        ag_rm = agent.curr_rm

        ag_xy = [agent.x, agent.y]
        dist_curr_rm_door = 10
        dist_goal_door = 10
        ag_door = self.rooms[ag_rm].door
        goal_door = self.rooms[goal_rm].door

        # Euclidean distance to the doors
        if ag_door:
            dist_curr_rm_door = dist(ag_xy, self.rooms[ag_rm].door)
        if goal_door:
            dist_goal_door = dist(ag_xy, self.rooms[goal_rm].door)

        # If in the goal room or door of the goal room
        # KEEP THE 0.1 VALUE THE SAME AS CHECK IN ROOM.IN_ROOM!!! Otherwise shit breaks.
        if agent.curr_rm == goal_rm or dist_goal_door < 0.1:
            poi_ag_num = (nn_max_idx) % it_per_rm   # Add one to make index line up for modulo calculation
            goal = self.act_in_rm(agent, poi_ag_num, goal_rm)

        # If in the hall or the door of another room, go to the door of the goal room
        elif agent.curr_rm == self.n_rooms - 1 or dist_curr_rm_door < 0.1:
            goal = self.rooms[goal_rm].door + [None]

        # Otherwise, exit the current room
        else:
            goal = self.rooms[ag_rm].door + [None]

        return goal

    def act_in_rm(self, agent, poi_ag_num, rm_num):
        if poi_ag_num < self.n_poi_types:
            ag_or_poi = self.rooms[rm_num].pois
            cls = 'POI'
        else:
            poi_ag_num -= self.n_poi_types
            ag_or_poi = self.rooms[rm_num].agents_in_rm
            cls = 'Ag'

        goal = [None, None, None]
        # Get the closest POI/ag of that type
        cl_dist = 100
        ax, ay = agent.x, agent.y
        # Loop through poi/ag in the current room
        for a_or_p in ag_or_poi:
            # Only check poi/ag that are of the correct type
            if a_or_p.type != poi_ag_num:
                continue
            if cls == 'POI':
                if a_or_p.observed:
                    continue
            px, py = a_or_p.x, a_or_p.y
            dist = sqrt((ax - px) ** 2 + (ay - py) ** 2)
            if dist < cl_dist:
                cl_dist = dist
                goal[:2] = [px, py]
                # If it is a POI, save the POI as the last element to pass to the agent
                # This allows for a later check to see if the agent has successfully observed the POI
                if cls == 'POI':
                    goal[2] = a_or_p

        return goal

    def get_action_size(self):
        """
        Agent can choose a POI type or agent type in any room
        Actions are therefore (n_poi_types + n_agent_types) * n_rooms
        :return:
        """
        # Subtract 1 from rooms as to not include the hallway
        return (self.n_rooms - 1) * (self.n_poi_types)  # + self.n_agent_types)

    def agent_room_times(self):
        all_times = []
        for agent in self.agents:
            time_arr = np.array(agent.time_in_rm)
            all_times.append(time_arr / sum(time_arr))
        return all_times

    ################################# Reward Functions #################################
    def multiG(self):
        g = np.zeros(self.n_poi_types)
        for poi in self.pois:
            g[poi.type] += poi.successes * poi.value
        return g

    def multiD(self):
        d = np.zeros((self.n_poi_types, self.n_agents))
        for poi in self.pois:
            d[poi.type] = d[poi.type] + poi.D_vec * poi.value
        return d

    # returns global reward based on POI values
    def G(self):
        g = 0
        for poi in self.pois:
            g += poi.successes * poi.value
        return g

    def D(self):
        d = np.zeros(self.n_agents)
        for poi in self.pois:
            d = d + poi.D_vec * poi.value
        return d

    def Dpp(self):
        d = np.zeros(self.n_agents)
        for poi in self.pois:
            d = d + poi.Dpp_vec * poi.value
        return d

    def high_level_G(self):
        g = self.multiG()
        possible_G = np.sum(self.p.rooms, axis=0)
        if g[0] < int(possible_G[0]):
            return 0
        elif g[1] > 0:
            return 0
        else:
            return 1

    def view(self, t):
        plt.ion()
        plt.clf()
        plt.xlim([-1, self.size + 1])
        plt.ylim([-1, self.size + 1])

        ax = plt.gca()
        for room in self.rooms:
            bounds = room.bounds
            ax.add_patch(Rectangle(bounds[0], bounds[1][0] - bounds[0][0], bounds[1][1] - bounds[0][1],
                                   edgecolor='black',
                                   facecolor='none',
                                   zorder=-1,
                                   lw=1))
        for room in self.rooms:
            door = room.door
            if door is not None:
                plt.scatter(door[0], door[1], s=500, c="black", marker="_")
        poi = np.array([[poi.x, poi.y, poi.type] for poi in self.pois]).T
        color = ["r", "b", "y", "c"]
        colors = [color[int(p)] for p in poi[2]]
        plt.scatter(poi[0], poi[1], c=colors, marker="s")

        agent = np.array([[agent.x, agent.y, agent.type] for agent in self.agents]).T
        color = ["b", "y", "c"]
        colors = [color[int(p)] for p in agent[2]]
        plt.scatter(agent[0], agent[1], c=colors, marker="o")
        pth = path.join(getcwd(), 'rollouts', f't{self.p.trial_num:02d}_{self.p.rew_str}_{t}.png')

        plt.savefig(pth)

        # plt.pause(1 / 10)

    def draw(self, t):
        # TODO: Update to include walls for rooms
        if self.vis == 0:
            self.vis = 1
            plt.ion()
        agent_offset = np.random.normal(0, 0.5, (self.n_agents, 2))
        plt.clf()
        xy = np.array([[poi.x, poi.y] for poi in self.pois])
        XY = np.array([[agent.x, agent.y] for agent in self.agents]) + agent_offset
        # alpha = [1 - poi.refresh_idx / poi.refresh_rate for poi in self.pois]
        col = [poi.poi_type for poi in self.pois]
        alpha = np.array([poi.active for poi in self.pois], dtype=float)
        alpha[alpha < 0.1] = 0.2

        sizes = [poi.value * 20 + 10 for poi in self.pois]

        plt.scatter(xy[:, 0], xy[:, 1], marker="s", s=sizes, c=col, alpha=alpha, vmin=0, vmax=1)
        plt.scatter(XY[:, 0], XY[:, 1], marker="o")
        plt.ylim([0, self.size])
        plt.xlim([0, self.size])

        # plt.show()
        # sleep(0.1)
        pth = path.join(getcwd(), 'rollouts', self.p.fname_prepend + 't{:02d}_{}.png'.format(self.p.trial_num, t))

        plt.savefig(pth)


if __name__ == "__main__":
    from teaming.parameters00 import Parameters as p

    env = DiscreteRoverDomain(p)
    env.view()
    env.joint_state()
